{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79de7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da33c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 10000, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, d_model)  # (L, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0))  # (1, L, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, L, d_model)\n",
    "        x = x + self.pe[:, : x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "def causal_mask(L: int, device=None):\n",
    "    # shape: (L, L), True where masked\n",
    "    mask = torch.triu(torch.ones(L, L, device=device, dtype=torch.bool), diagonal=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        d_model: int = 128,\n",
    "        nhead: int = 8,\n",
    "        num_layers: int = 4,\n",
    "        dim_feedforward: int = 256,\n",
    "        dropout: float = 0.1,\n",
    "        out_dim: int = 1,  # = num_classes для классификации\n",
    "        problem_type: str = \"regression\",  # or \"classification\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.problem_type = problem_type\n",
    "        self.input_proj = nn.Linear(n_features, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, dropout=dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        # x: (B, L, n_features)\n",
    "        B, L, _ = x.size()\n",
    "        h = self.input_proj(x)\n",
    "        h = self.pos_enc(h)\n",
    "        mask = causal_mask(L, device=x.device)  # (L, L) True=masked\n",
    "        h = self.encoder(h, mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        logits = self.head(h)  # (B, L, out_dim)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb16964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/frames_errors.csv\", header=None)\n",
    "df.columns = [\n",
    "    \"block_id\",\n",
    "    \"frame_idx\",\n",
    "    \"E_mu_Z\",\n",
    "    \"E_mu_phys_est\",\n",
    "    \"E_mu_X\",\n",
    "    \"E_nu1_X\",\n",
    "    \"E_nu2_X\",\n",
    "    \"E_nu1_Z\",\n",
    "    \"E_nu2_Z\",\n",
    "    \"N_mu_X\",\n",
    "    \"M_mu_XX\",\n",
    "    \"M_mu_XZ\",\n",
    "    \"M_mu_X\",\n",
    "    \"N_mu_Z\",\n",
    "    \"M_mu_ZZ\",\n",
    "    \"M_mu_Z\",\n",
    "    \"N_nu1_X\",\n",
    "    \"M_nu1_XX\",\n",
    "    \"M_nu1_XZ\",\n",
    "    \"M_nu1_X\",\n",
    "    \"N_nu1_Z\",\n",
    "    \"M_nu1_ZZ\",\n",
    "    \"M_nu1_Z\",\n",
    "    \"N_nu2_X\",\n",
    "    \"M_nu2_XX\",\n",
    "    \"M_nu2_XZ\",\n",
    "    \"M_nu2_X\",\n",
    "    \"N_nu2_Z\",\n",
    "    \"M_nu2_ZZ\",\n",
    "    \"M_nu2_Z\",\n",
    "    \"nTot\",\n",
    "    \"bayesImVoltage\",\n",
    "    \"opticalPower\",\n",
    "    \"polarizerVoltages[0]\",\n",
    "    \"polarizerVoltages[1]\",\n",
    "    \"polarizerVoltages[2]\",\n",
    "    \"polarizerVoltages[3]\",\n",
    "    \"temp_1\",\n",
    "    \"biasVoltage_1\",\n",
    "    \"temp_2\",\n",
    "    \"biasVoltage_2\",\n",
    "    \"synErr\",\n",
    "    \"N_EC_rounds\",\n",
    "    \"maintenance_flag\",\n",
    "    \"estimator_name\",\n",
    "    \"f_EC\",\n",
    "    \"E_mu_Z_est\",\n",
    "    \"R\",\n",
    "    \"s\",\n",
    "    \"p\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3844663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_features = [\n",
    "    \"block_id\",\n",
    "    \"frame_idx\",\n",
    "]\n",
    "\n",
    "phys_gt_features = [\n",
    "    \"E_mu_Z\",\n",
    "    \"E_mu_X\",\n",
    "    \"E_nu1_X\",\n",
    "    \"E_nu2_X\",\n",
    "    \"E_nu1_Z\",\n",
    "    \"E_nu2_Z\",\n",
    "    \"N_mu_X\",\n",
    "    \"M_mu_XX\",\n",
    "    \"M_mu_XZ\",\n",
    "    \"M_mu_X\",\n",
    "    \"N_mu_Z\",\n",
    "    \"M_mu_ZZ\",\n",
    "    \"M_mu_Z\",\n",
    "    \"N_nu1_X\",\n",
    "    \"M_nu1_XX\",\n",
    "    \"M_nu1_XZ\",\n",
    "    \"M_nu1_X\",\n",
    "    \"N_nu1_Z\",\n",
    "    \"M_nu1_ZZ\",\n",
    "    \"M_nu1_Z\",\n",
    "    \"N_nu2_X\",\n",
    "    \"M_nu2_XX\",\n",
    "    \"M_nu2_XZ\",\n",
    "    \"M_nu2_X\",\n",
    "    \"N_nu2_Z\",\n",
    "    \"M_nu2_ZZ\",\n",
    "    \"M_nu2_Z\",\n",
    "]\n",
    "\n",
    "phys_features = [\n",
    "    \"bayesImVoltage\",\n",
    "    \"opticalPower\",\n",
    "    \"polarizerVoltages[0]\",\n",
    "    \"polarizerVoltages[1]\",\n",
    "    \"polarizerVoltages[2]\",\n",
    "    \"polarizerVoltages[3]\",\n",
    "    \"temp_1\",\n",
    "    \"biasVoltage_1\",\n",
    "    \"temp_2\",\n",
    "    \"biasVoltage_2\",\n",
    "]\n",
    "\n",
    "est_features = [\n",
    "    # \"E_mu_phys_est\",\n",
    "    \"E_mu_Z_est\",\n",
    "    \"R\",\n",
    "    \"s\",\n",
    "    \"p\",\n",
    "]\n",
    "\n",
    "proxy_features = [\n",
    "    \"N_EC_rounds\",\n",
    "    # \"f_EC\",\n",
    "]\n",
    "\n",
    "df = df[id_features + phys_gt_features + phys_features + est_features + proxy_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf4401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_features(df, features, lag):\n",
    "    df = df.copy()\n",
    "    lagged_features = []\n",
    "\n",
    "    for feature in features:\n",
    "        for l in lag:\n",
    "            df[f\"{feature}_lag_{l}\"] = df.groupby(\"block_id\")[feature].shift(l)\n",
    "            lagged_features.append(f\"{feature}_lag_{l}\")\n",
    "\n",
    "    df = df.bfill().ffill()\n",
    "    return df, lagged_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad25233",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_create = phys_features + phys_gt_features + est_features\n",
    "df, lagged_features = lag_features(df, features_to_create, lag=[2, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b83b703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def categorize_n_ec_rounds(n):\n",
    "    if n == 1 or n == 2 or n == 3:\n",
    "        return 1\n",
    "    elif 4 <= n <= 10:\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "\n",
    "df[\"N_EC_rounds_cat\"] = df[\"N_EC_rounds\"].apply(categorize_n_ec_rounds)\n",
    "df[\"N_EC_rounds_cat\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0d41a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 326221\n"
     ]
    }
   ],
   "source": [
    "# Test (Val)\n",
    "start_idx = df[(df[\"block_id\"] == 1489460492) & (df[\"frame_idx\"] == 99)].index[0]\n",
    "end_idx = df[(df[\"block_id\"] == 1840064900) & (df[\"frame_idx\"] == 101)].index[0]\n",
    "\n",
    "test_df = df.loc[start_idx:end_idx].copy()\n",
    "assert len(test_df) == 2000, \"Test (Val) set size is not 2000 rows\"\n",
    "\n",
    "# Train\n",
    "all_block_ids = df[\"block_id\"].unique()\n",
    "train_blocks = [bid for bid in all_block_ids if bid not in test_df[\"block_id\"].values]\n",
    "\n",
    "train_df = df[df[\"block_id\"].isin(train_blocks)]\n",
    "\n",
    "print(f\"Train: {len(train_df['block_id'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85be54a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = phys_features + lagged_features + [\"E_mu_Z_est\", \"R\", \"s\", \"p\"]\n",
    "target_col = \"N_EC_rounds_cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03b06884",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df[feature_cols])\n",
    "\n",
    "train_df.loc[:, feature_cols] = scaler.transform(train_df[feature_cols])\n",
    "test_df.loc[:, feature_cols] = scaler.transform(test_df[feature_cols])\n",
    "\n",
    "train_df.loc[:, feature_cols] = train_df[feature_cols].astype(np.float32)\n",
    "test_df.loc[:, feature_cols] = test_df[feature_cols].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14f33685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seqences(df, feature_cols, target_col):\n",
    "    groups = df.groupby(\"block_id\")\n",
    "    sequences = []\n",
    "    for block_id, g in groups:\n",
    "        x = torch.tensor(g[feature_cols].values, dtype=torch.float32)  # (L_i, F)\n",
    "        y = torch.tensor(g[target_col].values, dtype=torch.float32).unsqueeze(-1)  # (L_i, 1)\n",
    "        sequences.append((x, y))\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd399f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs = get_seqences(train_df, feature_cols, target_col)\n",
    "val_seqs = get_seqences(test_df, feature_cols, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f733cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, seqs):\n",
    "        self.seqs = seqs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.seqs[idx]\n",
    "\n",
    "\n",
    "def collate_pad(batch, pad_value: float = 0.0):\n",
    "    # batch: list of (x_i: (L_i,F), y_i: (L_i,1))\n",
    "    xs, ys = zip(*batch)\n",
    "    lengths = torch.tensor([t.size(0) for t in xs], dtype=torch.long)  # (B,)\n",
    "    X = torch.nn.utils.rnn.pad_sequence(\n",
    "        xs, batch_first=True, padding_value=pad_value\n",
    "    )  # (B, Lmax, F)\n",
    "    Y = torch.nn.utils.rnn.pad_sequence(ys, batch_first=True, padding_value=0.0)  # (B, Lmax, 1)\n",
    "    B, Lmax, _ = X.shape\n",
    "    ar = torch.arange(Lmax).expand(B, Lmax)\n",
    "    pad_mask = ar >= lengths.unsqueeze(1)  # True там, где паддинг: (B, Lmax), bool\n",
    "    loss_mask = (~pad_mask).unsqueeze(-1)  # (B, Lmax, 1) для маскирования лосса\n",
    "    return X, Y, pad_mask, loss_mask, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ec4f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SeqDataset(train_seqs)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_pad)\n",
    "\n",
    "val_dataset = SeqDataset(val_seqs)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cc4820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_features = len(feature_cols)\n",
    "num_classes = 3\n",
    "model = TimeSeriesTransformer(\n",
    "    n_features=n_features,\n",
    "    out_dim=num_classes,\n",
    "    d_model=128,\n",
    "    dim_feedforward=256,\n",
    "    problem_type=\"classification\",\n",
    ").to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92ffccc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train loss: 0.938366 | train acc: 0.5946 | val loss: 0.808101 | val acc: 0.6515\n",
      "Epoch 02 | train loss: 0.871455 | train acc: 0.6110 | val loss: 0.781694 | val acc: 0.6625\n",
      "Epoch 03 | train loss: 0.837176 | train acc: 0.6256 | val loss: 0.747830 | val acc: 0.6645\n",
      "Epoch 04 | train loss: 0.807745 | train acc: 0.6390 | val loss: 0.728192 | val acc: 0.6660\n",
      "Epoch 05 | train loss: 0.781234 | train acc: 0.6516 | val loss: 0.701952 | val acc: 0.6790\n",
      "Epoch 06 | train loss: 0.749863 | train acc: 0.6664 | val loss: 0.704238 | val acc: 0.6800\n",
      "Epoch 07 | train loss: 0.733924 | train acc: 0.6730 | val loss: 0.673086 | val acc: 0.6905\n",
      "Epoch 08 | train loss: 0.712127 | train acc: 0.6819 | val loss: 0.659776 | val acc: 0.7025\n",
      "Epoch 09 | train loss: 0.698786 | train acc: 0.6879 | val loss: 0.657309 | val acc: 0.7105\n",
      "Epoch 10 | train loss: 0.689546 | train acc: 0.6908 | val loss: 0.638429 | val acc: 0.7185\n",
      "Epoch 11 | train loss: 0.678593 | train acc: 0.6970 | val loss: 0.629715 | val acc: 0.7200\n",
      "Epoch 12 | train loss: 0.669948 | train acc: 0.7004 | val loss: 0.625300 | val acc: 0.7285\n",
      "Epoch 13 | train loss: 0.662290 | train acc: 0.7034 | val loss: 0.623732 | val acc: 0.7280\n",
      "Epoch 14 | train loss: 0.655943 | train acc: 0.7061 | val loss: 0.610272 | val acc: 0.7320\n",
      "Epoch 15 | train loss: 0.649934 | train acc: 0.7094 | val loss: 0.612092 | val acc: 0.7325\n",
      "Epoch 16 | train loss: 0.647478 | train acc: 0.7108 | val loss: 0.610210 | val acc: 0.7390\n",
      "Epoch 17 | train loss: 0.643047 | train acc: 0.7131 | val loss: 0.607621 | val acc: 0.7335\n",
      "Epoch 18 | train loss: 0.639701 | train acc: 0.7142 | val loss: 0.604143 | val acc: 0.7475\n",
      "Epoch 19 | train loss: 0.636528 | train acc: 0.7160 | val loss: 0.603871 | val acc: 0.7395\n",
      "Epoch 20 | train loss: 0.631780 | train acc: 0.7176 | val loss: 0.600824 | val acc: 0.7455\n",
      "Epoch 21 | train loss: 0.629428 | train acc: 0.7197 | val loss: 0.597896 | val acc: 0.7510\n",
      "Epoch 22 | train loss: 0.626021 | train acc: 0.7210 | val loss: 0.591689 | val acc: 0.7455\n",
      "Epoch 23 | train loss: 0.621647 | train acc: 0.7223 | val loss: 0.592798 | val acc: 0.7395\n",
      "Epoch 24 | train loss: 0.618857 | train acc: 0.7236 | val loss: 0.603782 | val acc: 0.7400\n",
      "Epoch 25 | train loss: 0.617157 | train acc: 0.7247 | val loss: 0.592430 | val acc: 0.7420\n",
      "Epoch 26 | train loss: 0.613495 | train acc: 0.7255 | val loss: 0.584196 | val acc: 0.7455\n",
      "Epoch 27 | train loss: 0.607766 | train acc: 0.7293 | val loss: 0.581275 | val acc: 0.7495\n",
      "Epoch 28 | train loss: 0.604342 | train acc: 0.7303 | val loss: 0.580955 | val acc: 0.7395\n",
      "Epoch 29 | train loss: 0.601990 | train acc: 0.7317 | val loss: 0.579270 | val acc: 0.7410\n",
      "Epoch 30 | train loss: 0.597664 | train acc: 0.7335 | val loss: 0.577934 | val acc: 0.7425\n",
      "Epoch 31 | train loss: 0.596777 | train acc: 0.7335 | val loss: 0.577110 | val acc: 0.7455\n",
      "Epoch 32 | train loss: 0.590861 | train acc: 0.7366 | val loss: 0.568682 | val acc: 0.7455\n",
      "Epoch 33 | train loss: 0.588341 | train acc: 0.7378 | val loss: 0.565566 | val acc: 0.7440\n",
      "Epoch 34 | train loss: 0.585832 | train acc: 0.7388 | val loss: 0.576409 | val acc: 0.7475\n",
      "Epoch 35 | train loss: 0.585392 | train acc: 0.7397 | val loss: 0.571868 | val acc: 0.7465\n",
      "Epoch 36 | train loss: 0.580904 | train acc: 0.7410 | val loss: 0.570667 | val acc: 0.7450\n",
      "Epoch 37 | train loss: 0.579027 | train acc: 0.7422 | val loss: 0.564571 | val acc: 0.7460\n",
      "Epoch 38 | train loss: 0.574812 | train acc: 0.7445 | val loss: 0.560680 | val acc: 0.7450\n",
      "Epoch 39 | train loss: 0.572078 | train acc: 0.7453 | val loss: 0.562222 | val acc: 0.7500\n",
      "Epoch 40 | train loss: 0.572570 | train acc: 0.7451 | val loss: 0.559988 | val acc: 0.7530\n",
      "Epoch 41 | train loss: 0.568374 | train acc: 0.7469 | val loss: 0.555317 | val acc: 0.7570\n",
      "Epoch 42 | train loss: 0.564271 | train acc: 0.7486 | val loss: 0.557856 | val acc: 0.7565\n",
      "Epoch 43 | train loss: 0.561358 | train acc: 0.7513 | val loss: 0.561583 | val acc: 0.7585\n",
      "Epoch 44 | train loss: 0.558961 | train acc: 0.7516 | val loss: 0.552421 | val acc: 0.7575\n",
      "Epoch 45 | train loss: 0.557428 | train acc: 0.7518 | val loss: 0.553515 | val acc: 0.7450\n",
      "Epoch 46 | train loss: 0.555411 | train acc: 0.7530 | val loss: 0.569106 | val acc: 0.7545\n",
      "Epoch 47 | train loss: 0.552283 | train acc: 0.7548 | val loss: 0.547076 | val acc: 0.7600\n",
      "Epoch 48 | train loss: 0.549991 | train acc: 0.7562 | val loss: 0.545709 | val acc: 0.7655\n",
      "Epoch 49 | train loss: 0.548529 | train acc: 0.7560 | val loss: 0.548194 | val acc: 0.7590\n",
      "Epoch 50 | train loss: 0.547055 | train acc: 0.7576 | val loss: 0.541963 | val acc: 0.7615\n",
      "Epoch 51 | train loss: 0.544478 | train acc: 0.7580 | val loss: 0.542683 | val acc: 0.7575\n",
      "Epoch 52 | train loss: 0.540976 | train acc: 0.7595 | val loss: 0.541178 | val acc: 0.7655\n",
      "Epoch 53 | train loss: 0.537829 | train acc: 0.7614 | val loss: 0.555818 | val acc: 0.7420\n",
      "Epoch 54 | train loss: 0.538707 | train acc: 0.7608 | val loss: 0.546990 | val acc: 0.7555\n",
      "Epoch 55 | train loss: 0.535620 | train acc: 0.7622 | val loss: 0.545066 | val acc: 0.7565\n",
      "Epoch 56 | train loss: 0.532540 | train acc: 0.7641 | val loss: 0.546525 | val acc: 0.7530\n",
      "Epoch 57 | train loss: 0.532525 | train acc: 0.7641 | val loss: 0.539174 | val acc: 0.7580\n",
      "Epoch 58 | train loss: 0.529492 | train acc: 0.7656 | val loss: 0.547724 | val acc: 0.7490\n",
      "Epoch 59 | train loss: 0.527239 | train acc: 0.7667 | val loss: 0.551319 | val acc: 0.7625\n",
      "Epoch 60 | train loss: 0.527001 | train acc: 0.7665 | val loss: 0.544222 | val acc: 0.7580\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m     20\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m train_loss_sum += \u001b[43m(\u001b[49m\u001b[43mloss_map\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_mask\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m train_n += loss_mask.sum().item()\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Accuracy\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    train_loss_sum, train_n = 0.0, 0.0\n",
    "    train_correct, train_total = 0, 0\n",
    "\n",
    "    for X, Y, pad_mask, loss_mask, lengths in train_loader:\n",
    "        X, Y, pad_mask, loss_mask = (\n",
    "            X.to(device),\n",
    "            Y.to(device).long().squeeze(-1),  # (B, Lmax)\n",
    "            pad_mask.to(device),\n",
    "            loss_mask.to(device),\n",
    "        )\n",
    "        pred = model(X, src_key_padding_mask=pad_mask)  # (B, Lmax, num_classes)\n",
    "        loss_map = loss_fn(pred.permute(0, 2, 1), Y)  # (B, Lmax)\n",
    "        loss = (loss_map * loss_mask.squeeze(-1)).sum() / loss_mask.sum().clamp_min(1)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_sum += (loss_map * loss_mask.squeeze(-1)).sum().item()\n",
    "        train_n += loss_mask.sum().item()\n",
    "\n",
    "        # Accuracy\n",
    "        preds = pred.argmax(dim=-1)  # (B, Lmax)\n",
    "        train_correct += ((preds == Y) * loss_mask.squeeze(-1)).sum().item()\n",
    "        train_total += loss_mask.sum().item()\n",
    "\n",
    "    train_loss = train_loss_sum / max(train_n, 1.0)\n",
    "    train_acc = train_correct / max(train_total, 1.0)\n",
    "\n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    val_loss_sum, val_n = 0.0, 0.0\n",
    "    val_correct, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y, pad_mask, loss_mask, lengths in val_loader:\n",
    "            X, Y, pad_mask, loss_mask = (\n",
    "                X.to(device),\n",
    "                Y.to(device).long().squeeze(-1),\n",
    "                pad_mask.to(device),\n",
    "                loss_mask.to(device),\n",
    "            )\n",
    "            pred = model(X, src_key_padding_mask=pad_mask)\n",
    "            loss_map = loss_fn(pred.permute(0, 2, 1), Y)\n",
    "            val_loss_sum += (loss_map * loss_mask.squeeze(-1)).sum().item()\n",
    "            val_n += loss_mask.sum().item()\n",
    "\n",
    "            # Accuracy\n",
    "            preds = pred.argmax(dim=-1)\n",
    "            val_correct += ((preds == Y) * loss_mask.squeeze(-1)).sum().item()\n",
    "            val_total += loss_mask.sum().item()\n",
    "\n",
    "    val_loss = val_loss_sum / max(val_n, 1.0)\n",
    "    val_acc = val_correct / max(val_total, 1.0)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | train loss: {train_loss:.6f} | train acc: {train_acc:.4f} | val loss: {val_loss:.6f} | val acc: {val_acc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7089d4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
